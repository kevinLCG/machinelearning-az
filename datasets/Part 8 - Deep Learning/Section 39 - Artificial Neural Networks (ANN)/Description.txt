El llamado Deep Learning es la rama más emocionante y poderosa del mundo del Machine Learning. Los modelos de Deep Learning sirven para una gran variedad de tareas muy complejas:

    Redes Neuronales Artificiales para problemas de  Regresión y Clasificación

    Redes Neuronales Convolucionales para problemas de Visión por Computador

    Redes Neuronales Recurrentes para el Análisis de Series Temporales

    Mapas Auto Organizados para Extracción de Rasgos

    Máquinas de Boltzmann Profundas para Sistemas de Recomendación

    Codificadores automáticos para Sistemas de Recomendación

En esta parte del curso nos centraremos en entender y aprender a implementar los siguientes modelos de Deep Learning:

    Redes Neuronales Artificiales para problemas de Empresa

    Redes Neuronales Convolucionales para problemas de Visión por Computador



#######################################################################################################
                                              TEMAS
#######################################################################################################

-------------- PERCEPTRON / NEURONA -----------------

A una red neuronal con una sola neurona en la capa oculta se llama perceptron.

* Capa de Entrada / Inputs
Recibe distintos datos de entrada del exterior. Los datos de entrada corresponden al valor de las variables independientes "X" para 1 observacion del dataset (claro que pueden tener rangos diferentes y por eso se estandarizan a la misma medis 0 y desviacion estandar 1); cada variable independientre entra a una neurona diferente de esta capa.
Estos valores de entrada se multiplicaran por un valor "w" (pesos) y se sumaran todos.
X1w1 + X2w2 + X2w2 + ... + Xnwn; D

* Capa(s) Oculta
Pueden haber muchas capas ocultas. Se procesa la informacion. Conectan a la capa de entrada con la de salida.
Paso 1:
Σ Xiwi
Paso 2:
Se le aplica al valor anterior una funcion de activacion para ver si la neurona debe activarse.
Paso 3:
Si este valor es suficientemente alto, a informacion que la neurona ha calculado se transmite a la siguiente capa


* Capa de salida
El valor de Salida "y" representa a la variabe dependiente y corresponde a la misma observacion que se recibio en el Input, puede ser un valor continuo, binario (si/no) o categoria.
Para el caso de salida existen tantas neuronas en la capa como categorias posibles y hay 2 para el caso de valores binarios.

Sinapsis
La neurona tiene que encontrar el valor optimo de los coeficientes/pesos "w", de modo que sea capaz de calcular el valor de salida ponderando cada peso por su valor de salida y sumarlos.

-------------- FUNCION DE ACTIVACION -----------------

Imaginemos que en un plano cartesiano el eje x representa el valor de la sumatoria "Σ Xiwi" y en el eje y estanlos valores de salida 0 y 1
Hay 4 principales funciones de activacion:

- Funcion escalon o funcio umbral
  A partr de un valor en x, el valor de salida pasa de 0 a 1. O se activa la neurona o no se activa.

- Funcion Sigmoide
  Es 1/(1+e^-x). Es una version suavizada de la funcion anterior y da como resultados valores entre 0 y 1, que se pueden interpretar como la probabilidad de que se active la neurona.

- Rectificador Lineal Unitario
  La mitad de la funcion esta pegada al cero y al pasar un punto en el eje x, comienza a crecer. Todo lo negativo se va a cero.

- Tangente Hiperbolica
  Es (1-e^-2x)/(1+e^-x). Tiene la misma forma que la funcion sigmoide. Esta funcion resulta en valores que van del -1 al 1.


-------------- ¿COMO FUNCIONAN LAS REDES NEURONALES? -----------------

Antes de entrar hay que definir la estructura de la red neuronal: no. de nodos de entrada, no. de capas ocultas, funciones de activacion, etc...

Tomando en cuenta que se tiene 1 capa oculta de varias neuronas;  la informacion de todas las variables entra a cada una de ellas. Cada neurona intenta obtener los coeficientes / pesos "w" mas optimos; entre mas cercanos a cero sean estos, significa que aportan menos informacion y si son 0, significa que esa variable no aporta informacion, esto significa que cada neurona le dara un peso diferente a cada una de las variables, dandole mas flexibilidad al modelo y la prediccion final se da ponderando cada una de las decisiones de las neuronas anteriores.


-------------- ¿COMO FUNCIONAN LAS REDES NEURONALES? -----------------

Se cuantifica la difirencia entre la "y" obtenida como resultado y la "yr" real, mediante la funcion de coste, generalmente dada por: 1/2*(y-yr)^2 (Ordinary Square Summ).
El objetivo es minimizar la funcion de coste, esto se "propaga hacia atras para modificar los pesos "w" eintentas que la funcion de coste este muy cercana al cero.

La red neuronal para ajustarse, hace predicciones con los pesos inicializados aleatoriamente para todas las observaciones,  se obtiene la funcion de coste "Σ 1/2*(y-yr)^2" y con esta informacion se actualizan los pesos "w" que multiplican al valor de las variables independientes.

NOTA: SE USAN LOS MISMOS PESOS PARA TODAS LAS OBSERVACIONES

-------------- GRADIENT DESCENT (BY BLOCKS) -----------------

Tecnica usada para ajustar los pesos "w", requiere que la funcion de coste sea convexa. 
La funcion de coste, para cada peso "w", tiene forma de parabola convexa y el valor objetivo se encuentra en el minimo de la parabola (el eje y representa el valor de la funcion de coste y el eje y el valor del peso "w").
Un primer enfoque para encontrar este "w" objetivo seria la "fuerza bruta" y probar todos los posibles pesos y elegir el mas bajo. Pero si los posibles valores de "w1" con miles y si a eso se le suman los posibles valores sel peso "w2" y asi sucesivamente, resulta computacionalmente imposible.

Para encontra una solucion de manera mas optina, lo que se hace es medir la pendiente en el punto actual, y si la pendiente es negativa se ir hacia la der. y si es positiva, hay que ir hacia la izq.
El"gradiente" es la direccion de maxima caida

-------------- STOCHASTIC GRADIENT DESCENT -----------------

Util cuando la funcion de coste no es convexa, como un polinomio de grado superior, suando hay operaciones intermedias, etc. Este metodo tiende a encontrar un MINIMO GLOBAL.

A diferencia del "gradiente descendiente normal" en donde se hace la prediccion de todas las observaciones y luego se ajustan los pesos, en este metodo se toma la primera observacion, se calcula el error y se ajustan los pesos, luego se toma la siguiente observacion, se calcula el error, se corrigen los pesos y asi sucesivamente...

Al calcular los pesos en cada iteracion, las fluctuaciones de la funcion son mas altas y los saltos de una iteracion a otra son superiores y esto hace que se converja al minimo global.
La desventaja es que es mas tardado al actualizar los pesos muy seguido.

-------------- BACK PROPAGATION (aprender de los errores) -----------------

Pasos:

1.- Los valores de los pesos "w" se inicializan con valores cercanos a 0 (pero no 0).
2.- Se introduce la primera observacion del dataset en la capa de entrada, cada caracteristica es un 
    nodo de entrada.
3.- Propagacion hacia adelante: de izq. a der., las neuronas se activan, de modo que la activacion de 
    cada una se limita por los pesos. La informacion va pasando entre las capas ocultas hasta llegar a la prediccion "y".
4.- Se mide el error generado al comparar la prediccion "y" con el valor verdadero "yr".
5.- Propagacion hacia atras: de derecha a izquierda, propagando el error hacia atras. Se actualizan 
    los pesos de acuerdo a que tanto afecten estos al error. El "ratio de apendizaje", indica cual es lo maximo que debe cambiar de una iteracion a la siguiente.
6.- Se repien los pasos 1-5 y se actualizan los pesos de cada observacion (Reinforcement Learining) o
    se repiten los pasos 1-5, pero actualizando los pesos despues de un conjunto de observaciones 
    (Batch Learning).
7.- Cuando todo el conjunto de Entrenamiento ha pasado por la Red Neuronal, se completa un epoch.
    Se debe eliegir un numero de epochs.